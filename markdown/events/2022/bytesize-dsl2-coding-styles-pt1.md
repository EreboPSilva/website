---
title: 'Bytesize: DSL2 Coding style recommendations (Part 1)'
subtitle: Maxime Garcia - Barncancerfonden, Stockholm, Sweden
type: talk
start_date: '2022-07-05'
start_time: '13:00 CEST'
end_date: '2022-07-05'
end_time: '13:30 CEST'
youtube_embed: https://www.youtube.com/watch?v=KnYPzZ0Dd-Y
location_url:
  - https://www.youtube.com/watch?v=KnYPzZ0Dd-Y
  - https://doi.org/10.6084/m9.figshare.20238969.v1
---

# nf-core/bytesize

Join us for our **weekly series** of short talks: **‚Äúnf-core/bytesize‚Äù**.

Just **15 minutes** + questions, we will be focussing on topics about using and developing nf-core pipelines.
These will be recorded and made available at <https://nf-co.re>
It is our hope that these talks / videos will build an archive of training material that can complement our documentation. Got an idea for a talk? Let us know on the [`#bytesize`](https://nfcore.slack.com/channels/bytesize) Slack channel!

## Bytesize: DSL2 Coding style recommendations (Part 1)

This week, Maxime Garcia ([@MaxUlysse](https://github.com/MaxUlysse)) will explain us what he thinks the perfect DSL2 coding style should be.

Come and join the ensuing discussion, it's going to be lively üòâ

<details markdown="1"><summary>Video transcription</summary>
**Note: The content has been edited for reader-friendliness**

[0:01](https://www.youtube.com/watch?v=KnYPzZ0Dd-Y&t=1)
Got it. I have a question. You can answer that. No, I'm sorry, do you? No, I don't know. Yes, hello. I'm hoping I pronounced your name right. Basically, the way we select the by-size topic, we ask for the community what they want to talk about, and we also we discuss it between ourselves, like in the NF core outreach team. So if you want to hear some specific by-size about any topics, don't hesitate to say that in our Slack channels, and we will mention that and think about it. I think that the first time I replied to a question before the talk even started. Very good. Are you going to do anything? So one more minute for everyone. You're going to cut before. There's always going to be like such a mess. Let's make sure. Yes, sorry, we are having a straining party here at SciLife and we are three in a room and just want to be sure that the microphone and the speakers are not like interacting with each other. But we are about to start. Go to the NF core. Can't do this now. OK, now that we kind of sorted all our problems. Welcome, everyone. I'm Francesca Gunnot, I'm the host today and here is Maxime and he is going to talk about coding styles with DSL2. And off to you. I'll share my screen. So hello, everyone, Maxime here. So today I'm doing another talk about like DSL2. This time I will try to focus a bit more about like some coding style recommendation. I will not talk much about syntax, but more about like organization of the code. So just quick overview. So first, what has changed with DSL2? You already know the answer to that, like since it's my second topic, what are modules? And so then last, what I think we should do with that. So to begin with everything, as usual, this is a disclaimer, like these are my own recommendation. I think some other people are agreeing with me on some of these views, but other developers might have like other views on that. And we are still trying to forge the best practice. We are still trying to get to figure out what is easier to read, what is easier to understand. So it might and it probably will still evolve when we are getting there and I might probably change view on some of these topics. But at the moment, this is what I think we should do. So what has changed with DSL2? So if we follow the Paolo announcement from like two years ago on the Nextflow blog, I think like I linked like the whole blog post. But for me, the most important phrase is this one. Like the module file is nothing more than a Nextflow script containing one or more process definitions that can be imported from another Nextflow script. So this is what has changed with DSL2 module. So and as you guessed, I will be talking about modules a lot in this talk. But what actually does that mean? What is a module? So of course, obviously a module is a module. If we follow this definition that would be just like so. A process can be a module as well. A sub-workflow can be a module and the workflow can be a module. And they all can be interlinked together, which can be a bit confusing, but actually it's pretty clear. But to get like even clearer, we agreed at NF-Core to have like some proper definition. So for us at NF-Core, a module is a single atomic process that can be called into like other script. A sub-workflow will be like a few chained modules. And then a workflow is an end-to-end pipeline. So with that, I think it's fairly simple. And with this definition, we can decide how we want to organize the code and how we want to do things properly. So I will explain what I think should be done. So for me, I think the code should be easy to read. That's why it's easy to understand. It's easy to share, easy to modify, and easy to contribute. Because that's what we want. We are all working in open source science. And yes, I think that's what we want. That's what this community is all about. It's about like sharing our code, sharing our work, and working together to achieve like these goals. So for me, that's what is the most important part. So now we are going like for some examples. So I followed like the same bit of code like from the module level to the sub-workflow level to the workflow level. Just to explain for me how all should work. So basically, the first statement, as we said, like all the code for the process is in the modules. That's the NFKL repository. So either we can have a local module within the pipeline or NFKL modules within the NFKL repository. So in this case, I'm going to showcase the Ensemble VIP module. So the code is fairly simple for like a module. We have like as usual the tag definitions, the labels that specify like the resources that we can decide on afterwards. Then we have the virtual environment or the containers that are specified for that. Here we have the input. So as usual for the input, first we have like the actual file that are like depending on the sample that we want to analyze. And then we have the reference file or the reference values that are needed for this. The monetary one and then we have all of the optional files. Then we can specify some outputs. So as usual, we have the version which is what we want in our NFKL module. Because that way we want to be sure that we can have the possibilities that we want. And then in this case, we have some optional output. Otherwise, you can have some regular like output indicator. We are doing also a when statement in the NFKL module. And then we have the popular part of the script, which actually just called the tool. And then of course, some extra specification to specify some extra arguments or other part from the code. And then at the end, we just specify the version. So this is just the part of the code which is like modular because that's what we wanted to do in NFKL. That way we can share the code with everyone. Then as a companion to that, we have some modular setup in the config file. So for that particular matter, closures are definitely our best friend. This is what I said like in my last talk and this view hasn't changed into that. So with the closure, you can really like dynamically specify like what you want inside. So at NFKL, we decided to use custom namespace like X directive that allow us to have like some specific namespace that we are using. So we are using them for the arguments, args, args2, args3. We are using them for the prefix. We can even be crazy and use that for when. And then we can also use closure and use other directive at the process level, such as the published year, which is fairly common to use, I guess. And if you're feeling very, very crazy, you can even go and change the container. And this is, for example, what we are doing at the moment in Sarek, still for this module. So here within Sarek at the moment, I'm having a condition to specify if I want this selector to be available or not, because otherwise we have some warnings that this process does not exist. And I just don't like to have like a lot of empty warning somewhere. So this is optional and I'm hoping we will get rid of that at some point. But here, this is just starting here. So we have a prefix for this specific tool that we want to use. So this is what will happen for this prefix. Here we have some arguments. So here in this case, it's a bit complicated, but basically what we do, we have like some basic arguments that will be used in all cases. And then we have some specific arguments that will be dependent of the input parameters that we specify on the command line. So in the end, it's actually fairly simple. We just join all of the arguments together. So this is a list. We join all that and then we trim to get just one single string in the end that we can directly put into the process with the args directive. Then, because in Sarek we like to do things differently, we specify a specific container in that case. And then we are using our publishdir directive to specify where we want to save our file. So depending on the extension of the file, we might have some specific location for that. And that's all. So in the end, it might look complicated, but it's actually fairly simple. Then at the sub-workflow level, so I think we can actually have several layers of sub-workflow. So for me, for the first layer of sub-workflow, I try to keep it as simple as possible. So what I want to do in this level, I just want to chain module together and just do some tiny channel manipulation if I have to. For example, you need to remap the output from one module to go into another module. Then yes, you can do that at this level. So it will, for example, arrive to that. So this is the sub-workflow that I'm using, that we are using in Sarek to actually call the module ensemble bit and then call the tabix module to tabix index the vcf file. So here this is what we are doing. As usual, we begin the workflow by taking the input data that is related to the sample and then all of the reference genome and optional values that we need to share. Then here, fairly simple, still I call the first module. I call the second module on the output from the first one, and I emit everything out. And of course, we gather all of the version for the tools that we use. So that's still in this case. If I want to go still, we are at sub-workflow, but then it's a fairly higher level because the sub-workflow, we can still include other sub-workflows in the sub-workflow. So what we can do there is that we can chain module together, or we can even like chain sub-workflows together, or sub-workflows and module and stuff like that. We can also manipulate channels, and we can do here also what I think is good to do here and not at any other, and not at the previous level, is to specify some execution logic with some if blocks. So it will look like that. So here, in this case, I'm calling three different sub-workflows. Actually, I'm just calling like two different sub-workflows. I'm calling the EnsemblVid that I just showed, the SNPEF sub-workflow. And I'm calling the EnsemblVid like twice because one time I want to use it as it is, and one time I want to use it on the output of the other sub-workflow. So I need to do an alias to actually be able to use it twice in the same sub-workflow. So as usual, I'm using the, it takes as an input the files that are related to the sample, and then as usual, the reference data and the other value. Then, as I explained earlier, I'm having this if statement to control the execution of the sub-workflow, and then I collect all the files that need to be collected. Same thing for that, same thing for that, and then we emit everything back. So if I think that if we follow this logic, I think we can get like some fairly easy to read and easy to understand organization of the module, sub-workflows, sub-workflows. And that way, it's easy to understand where to contribute, what to do, how to change, and how to evolve stuff. And then, at the workflow level, it's where we can do or where I think we should do everything else. So we can still, at the workflow level, call a single module. For example, you might want to call just the MultiQC module here at the workflow level. Of course, at the workflow level, we want to change several sub-workflows, because if we don't do that here, where are we going to do that? And then, of course, you still want to do some chain and manipulation, because yes, that's your main workflow script. That's where you want to do all of the magic. And, of course, the execution logic still happens over there. So this is what happens within CyberCAD at the moment. So still here, I have my execution logic. If my parameters, my input parameters are right, then I'm going to do that. And here, I just call my sub-workflow within the main workflow. And I gather all of the used software version in the report that I need to add. And then that's all. So for me, this is how we should organize our code for the module, depending on if we are at the module level, at the sub-workflow level, or at the workflow level. I also have some small syntax, like recommendation. We are trying to actually make proper recommendation guidelines on the DSL2 syntax. So we are working on the document with several other people from NF-Core. So if you want to contribute, the link is in the title here. And what I would like to say is, first, indentation is your friend. I think that's a fairly good statement. And I think a lot of people that are coming into bioinformatics will learn to code with Python. So I think indentation is already deeply ingrained into your habit. So let's continue working on that and let's keep indenting. It makes the code nice to look at. And I like to have a nice code to look at. Then I think, yes, in a process, I saw several different ways to collect several files, just to call it with the same parameters. And I think this is a proper way to do so. I try to enforce that in all of the JTK4 modules, but that might have escaped to me in some point. So this is, I think, fairly small and it's a small one-liner that is, I think, easy to understand. Then I think for the channel assignments, that's something that you want to do in a sub-workflow or in a workflow. I personally prefer to specify which channel I want to assign things to first. But some other people might prefer to have the channel in the end. I personally prefer the first version. I can see that some people coming from an R world prefer the second one. I think we really need to figure out with the community what we want to do. But I think I'm fairly going towards the first version of this line. Some last, I think, tips before I open the discussion. So please add comments to your code. It's good for you. Good for your colleagues or anyone who are going to have a look at the code. It's also good for future you because, yes, believe me, like two weeks from now or like three months from now, you're going to look again at your code and you're not going to remember why you did that. So you want some comments and right now you're your own best friend. You should be able to help yourself and do that. Also, I think it might be important, I notice this like sometimes within NextFlow, it might be difficult to differentiate between Q and value channels. And I think it could be a good idea to have that difference in mind from the beginning when you design your pipeline. Usually we do use value channels for reference, for all the reference files. And sometimes you don't understand why your process is not executed several times. It's because this channel that you believe was a value channel is actually a Q channel. So we need to be careful with that. Otherwise, I think like good tips would be like don't hesitate to ask questions. We have Slack. We are available on that. And I personally like to discuss with other people and stuff. So discuss, that's good. And yes, if you're on site with other people, have a coffee break. That's always good to start discussion with anyone else. So yes, as usual, I'd like to thank all of the institutions I work for and all of the institutions I work for and with on my project. I'd like to thank all of the institutions that are working with us on NF-Core. And I would like to thank all of the contributors that we had so far at the moment on NF-Core as well. If you need some help, of course, Slack as usual or everything else. If you need more help, we have some documentation and we have some previous bite sites that you can check up on that. Otherwise, I'm open for questions now. Yeah, thank you very much. I don't seem to show. Anyway, I have now opened the possibility for everyone to unmute themselves. So if you have any questions. Otherwise, we have also questions in the chat. OK, let's begin with a question in the chat. I do have a question. Oh, yeah, go ahead. OK, so I guess this is my first question, which is I'm wondering which specific Slack channel discusses Sarek in the NF-Core workspace. Because I haven't found any specific one for Sarek or it's just one of the existing channels. No, no, we have a specific Sarek channel to discuss about Sarek. OK. We have a specific channel for each pipeline and we do have a specific channel for every main topics. Otherwise, whenever you don't know anything, don't stay to go to the help channel and then we will direct you towards the right channel. OK, so it's like hash Sarek or something like that, right? Yes, hash Sarek. Oh, I see. OK. Oh, I found you. Thank you. So my other one is more of a comment as a follow up to what somebody said about the last comment about a user of a pipeline. Yes, so one or two are not really important. However, as a developer, it matters. Yes, so one to two conversion is a lot of work. So I tend to disagree with the first part of that, which is I say user, there's one or two are not really important. It is important because people are forced to actually go back to their code for those that actually did a DSL one without specifying which how their code should run since next to pretty much just force people by defaulting to DSL two and the code breaks. People are now forced to revisit their work. So if it wasn't that important, even for a user, then that would not be necessary. So I would tend to disagree and say it is, in fact, important to have pipelines in DSL two, whether it works in DSL one or not is relevant at this point. Because unless if, you know, you were thinking about the fact that DSL two would be default when you were coding and then you had made it very clear in the each of your modules or each of your scripts that it was DSL one enabled and stuff like that. Right. So I just wanted to point that out. But thanks. That was a great talk. Thank you. Yes. Also a question for Matthias. Okay, let's go. Yes, thank you for your great talk. And could you please elaborate a bit more on the extra arguments because I noticed, for example, that you've wrapped them in brackets in your module example. Go back to that. I haven't seen that so far. That was that or not at all? So we use them in the module? No, it was part of the code where you had the... So not this one either, right? Sorry, I'm trying to find it back. No, not this one. It must be the config where you provide the extra arguments. Are you saying like the for the publish dear thingy? No, exactly here. Exactly here. The param stopped that log tree or something. You've wrapped them here in brackets. Oh, yes. So here what we're doing, so we have everything like all of this extra arguments is in brackets. So that's a whole list. Yeah, that's the list. And then you... Not brackets, braces. No worries, it's fine. I always confuse the name of this, like even in French. So yes, here it's a list and for each element of this list, I specify like either like directly the params or directly here I have a tertiary like if, which is a bit long, sorry, which let me specify, okay, if, sorry, I'm going back there. So if this statement is true, then I have like this first string that will be considered. Otherwise, it will be like the second string, which is an empty string. Okay, yeah. And you basically just have the braces because for consistency. So if you don't evaluate the end, then it doesn't matter whether it's in braces or not. Or is that... No, no, I think the brackets are important because otherwise if we don't have that, then it's not the list and I want, basically what I want is that I have several arguments. I could make like one complicated if, like getting like all of the different like stuff, but what I want is that I want one string on which I can append like other arguments on top of that. This is completely clear. I'm just wondering about the limitations because sometimes it's like you've frapped curly braces still around. This is when you have a meta map in there. Ah, okay, you mean like that here? No, probably we should just take this. Yes, let's take this. There should be like some easy stuff for that. He's talking about when to use a closure. So the closure that's, for example, used in ext prefix. When you use a closure, the variables are evaluated during the task execution. But if you don't, so for example, the ext args, this one doesn't have the curly braces, so this is not within a closure, and you can't use any variables from the task execution context. And it's evaluated as soon as the config is loaded. So right at the beginning of the workflow before any of the tasks are executed, but if you use a closure, then one you can access variables within the task context, anything from input. But also, it means that kind of things like params out there and whatever, their evaluation is delayed until the execution of the task. Thank you. No, I understand what was the question. Sorry, I misunderstand you. Yes, then don't worry, we can have like a more detailed talk about that another day. Then there's a question from Phil. Hi everyone, thanks for the talk Maxime. I just wanted to reiterate something that came up in the comments on zoom just now, mostly in case anyone's watching this on YouTube at a later date. It was a really good comment about DSL one and two, and how running a DSL one pipeline with newer versions of next level crash in a slightly nasty way. But just to note that that's actually only a fairly specific version of next play where that happens. So Paolo switched it to DSL two by default, we saw these crashes happening. So we spoke to spoke to him and now the newer versions of next play since version 22.04.3 should automatically detect whether the workflow is DSL one or DSL two so you can go back to just running it without any flags and it should just work whether it's DSL one or whether it's DSL two, no nasty crashes anymore. But will we keep like DSL one inside the main next floor or at some point will we completely discontinue it? At some point it will be completely discontinued. So in the future, I think it's some time, it's mentioned in the next play blog. Yeah, I think it's planned for kind of mid 2023, the released versions of next play will stop supporting DSL one. And from that point, any DSL one pipelines will have to be run with older versions of next play. Yes, but then it's different because we can still install older version. Yeah, so the workflows will still run just not with latest version of next play. And yeah, if you're interested in converting workflows into DSL two, then we have a slack channel, an NF core dedicated to this topic called DSL two hyphen transition. And the same goes also for sub workflows. Thank you, Phil. There's another question from Olaitam. Okay, thanks. Okay, good. I'm going to make it brief. So my actual question is to Sarek again, which is that if I know, so you guys basically need to, for the reference genome, it has to be one of the existing ones, maybe GLC 38, 37 and the likes, right? So if I have a scientist, right, who has his own reference genome, basically, right, which is not one of the standard types, how do I handle the situation? Then it's really simple. We have these parameters that you can choose within Sarek. But can we talk about that more in the Sarek? For sure, this is going to be a long talk, for sure. Thanks. Just like don't pay to ping me on slack and I will answer directly. Perfect. Thank you. Okay, are there any more questions from the audience? There's a question for Kench. Phil also posted a link to Nextflow.io. It's the Nextflow blog post talking about the end of DSL one support. I'll put it in slack as well. Thank you. Also earlier Mahesh posted a link to Carpentries training material for coding practices. I will also leave this link in the selection. Maybe I can include that in my slides as well. Yes. Okay, if there are no more questions from the audience. Thank you so much Maxime for the talk. I also would like to thank the Chen and Zuckerberg initiative for funding these talks. And as always, you can continue these talks in, in slack on those hashtag bite size, or specific to any of the channels for different workflows, and thank you very much.

</details>
